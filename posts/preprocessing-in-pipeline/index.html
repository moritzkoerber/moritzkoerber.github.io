<!DOCTYPE html><html lang="en" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="How to apply preprocessing steps in a pipeline only to specific features" /><meta name="author" content="Moritz Körber" /><meta property="og:locale" content="en" /><meta name="description" content="The situation: You have a pipeline to standardize and automate preprocessing. Your data set contains features of at least two different data types that require different preprocessing steps. For example, categorical features may need to be converted into dummy variables but continuous features may need to be standardized. sci-kit learn has got you covered here since version 0.20! The function ColumnTransformer allows you to create column-specific pipeline steps! In this post, I show you how to use the function and talk about the advantages of preprocessing with a pipeline a bit. Let’s get started!" /><meta property="og:description" content="The situation: You have a pipeline to standardize and automate preprocessing. Your data set contains features of at least two different data types that require different preprocessing steps. For example, categorical features may need to be converted into dummy variables but continuous features may need to be standardized. sci-kit learn has got you covered here since version 0.20! The function ColumnTransformer allows you to create column-specific pipeline steps! In this post, I show you how to use the function and talk about the advantages of preprocessing with a pipeline a bit. Let’s get started!" /><link rel="canonical" href="https://moritzkoerber.github.io/posts/preprocessing-in-pipeline/" /><meta property="og:url" content="https://moritzkoerber.github.io/posts/preprocessing-in-pipeline/" /><meta property="og:site_name" content="Moritz Körber" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-10-11T00:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="How to apply preprocessing steps in a pipeline only to specific features" /><meta name="twitter:site" content="@moritzkoerber" /><meta name="twitter:creator" content="@Moritz Körber" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Moritz Körber"},"dateModified":"2023-10-12T21:09:23+02:00","datePublished":"2019-10-11T00:00:00+02:00","description":"The situation: You have a pipeline to standardize and automate preprocessing. Your data set contains features of at least two different data types that require different preprocessing steps. For example, categorical features may need to be converted into dummy variables but continuous features may need to be standardized. sci-kit learn has got you covered here since version 0.20! The function ColumnTransformer allows you to create column-specific pipeline steps! In this post, I show you how to use the function and talk about the advantages of preprocessing with a pipeline a bit. Let’s get started!","headline":"How to apply preprocessing steps in a pipeline only to specific features","mainEntityOfPage":{"@type":"WebPage","@id":"https://moritzkoerber.github.io/posts/preprocessing-in-pipeline/"},"url":"https://moritzkoerber.github.io/posts/preprocessing-in-pipeline/"}</script><title>How to apply preprocessing steps in a pipeline only to specific features | Moritz Körber</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Moritz Körber"><meta name="application-name" content="Moritz Körber"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/resources/images/pic.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Moritz Körber</a></div><div class="site-subtitle font-italic">Data science and other board games</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVE</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT ME</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/moritzkoerber" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/moritzkoerber" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href="https://medium.com/@moritzkoerber" aria-label="medium" target="_blank" rel="noopener"> <i class="fab fa-medium"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['moritzjkoerber','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/moritzkoerber/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>How to apply preprocessing steps in a pipeline only to specific features</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>How to apply preprocessing steps in a pipeline only to specific features</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Moritz Körber </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Oct 11, 2019, 12:00 AM +0200" >Oct 11, 2019<i class="unloaded">2019-10-11T00:00:00+02:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Thu, Oct 12, 2023, 9:09 PM +0200" >Oct 12, 2023<i class="unloaded">2023-10-12T21:09:23+02:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1420 words">7 min read</span></div></div><div class="post-content"><p>The situation: You have a pipeline to standardize and automate preprocessing. Your data set contains features of at least two different data types that require different preprocessing steps. For example, categorical features may need to be converted into dummy variables but continuous features may need to be standardized. sci-kit learn has got you covered here since version 0.20! The function <a href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html">ColumnTransformer</a> allows you to create column-specific pipeline steps! In this post, I show you how to use the function and talk about the advantages of preprocessing with a pipeline a bit. Let’s get started!</p><p>First, load the necessary libraries:</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="n">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">RepeatedStratifiedKFold</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
</pre></table></code></div></div><p>We will be working with the Titanic data set.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">titanic</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">./titanic.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="n">titanic</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>pclass<th>survived<th>name<th>sex<th>age<th>sibsp<th>parch<th>ticket<th>fare<th>cabin<th>embarked<th>boat<th>body<th>home.dest<tbody><tr><td>0<td>3<td>0<td>Mahon Miss. Bridget Delia<td>female<td>NaN<td>0<td>0<td>330924<td>7.8792<td>NaN<td>Q<td>NaN<td>NaN<td>NaN<tr><td>1<td>1<td>0<td>Clifford Mr. George Quincy<td>male<td>NaN<td>0<td>0<td>110465<td>52.0000<td>A14<td>S<td>NaN<td>NaN<td>Stoughton MA<tr><td>2<td>3<td>0<td>Yasbeck Mr. Antoni<td>male<td>27.0<td>1<td>0<td>2659<td>14.4542<td>NaN<td>C<td>C<td>NaN<td>NaN<tr><td>3<td>3<td>1<td>Tenglin Mr. Gunnar Isidor<td>male<td>25.0<td>0<td>0<td>350033<td>7.7958<td>NaN<td>S<td>13 15<td>NaN<td>NaN<tr><td>4<td>3<td>0<td>Kelly Mr. James<td>male<td>34.5<td>0<td>0<td>330911<td>7.8292<td>NaN<td>Q<td>NaN<td>70.0<td>NaN</table></div><h2 id="advantages-of-preprocessing-with-a-pipeline">Advantages of preprocessing with a pipeline</h2><p>We would like to predict whether a passenger has survived based on the available data. Before we train our model, some preprocessing has to be done. Why should we include preprocessing in our machine learning pipeline? Isn’t it easier to do everything beforehand, say with pandas?</p><p>First of all, it is convenient and makes the preprocessing steps and their order explicit, transparent and replicable. But there are three way more substantial reasons:</p><p>1) It allows to include the preprocessing steps in the hyperparameter tuning (I’ll come back to that in another post).</p><p>2) It saves you from making the mistake of using any test data for model training or decisions on the model (e. g., classifier parameters), also known as <em>data leakage</em>. This pitfall lurks, for example, when you use scalers or are imputing missing values. Avoiding this is crucial to obtaining valid model performance estimates. The preprocessing steps declared in the pipeline are guaranteed to be only performed based on training data (or training folds in cross-validation).</p><p>3) It guarantees that your data is always preprocessed the same way. This is important, for example, if a categorical feature has a category in the test set that does not occur in the training set. I’ll give you an example: Let’s say your training data contains a feature <code class="language-plaintext highlighter-rouge">review_status</code>, which indicates whether a transaction has already been reviewed. It may feature the following two categories:</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">review_status</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">not reviewed</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">reviewed</span><span class="sh">'</span><span class="p">]</span>
</pre></table></code></div></div><p>However, in your test data, there is one more category, <code class="language-plaintext highlighter-rouge">'externally reviewed'</code>, which does not appear in the training set. Now if you use <code class="language-plaintext highlighter-rouge">pandas.get_dummies()</code>, you will encounter two problems:</p><p>1) If novel data comes in observation by observation, using <code class="language-plaintext highlighter-rouge">pandas.get_dummies()</code> simply makes no sense.</p><p>2) You end up with one additional feature/column in the test set compared to the training set. But your model is trained on the training set and does not know this column. Vice versa, if the category is missing in the test set, your model expects one more feature. <code class="language-plaintext highlighter-rouge">OneHotEncoder()</code>, as all pipeline steps, first calls the <code class="language-plaintext highlighter-rouge">.fit()</code> method and then the <code class="language-plaintext highlighter-rouge">.transform()</code> method on the training set but only <code class="language-plaintext highlighter-rouge">.transform()</code> on the test set. Thus, the categories are derived only from the unique categories in the training set! You can explictly declare what happens if an unknown category is encountered by setting the <code class="language-plaintext highlighter-rouge">handle_unknown</code> parameter: <code class="language-plaintext highlighter-rouge">handle_unknown = 'error'</code> throws an error if an unknown category is encountered, while <code class="language-plaintext highlighter-rouge">handle_unknown = 'ignore'</code> makes the transformer ignore the category. Hence, once fit, <code class="language-plaintext highlighter-rouge">OneHotEncoder()</code> produces the same output every time it is applied to new data. And this is easy for our model to digest.</p><h2 id="creating-a-columntransformer">Creating a ColumnTransformer</h2><p>Okay, let’s create a preprocessing pipeline now. We wish to create dummy variables for the categorical features and to standardize the continuous features. For this purpose, we put everything in a <code class="language-plaintext highlighter-rouge">ColumnTransformer</code>. We begin with the categoricals: First, we need to name the step: <code class="language-plaintext highlighter-rouge">'onehot'</code>. Then we need to specify the transformer, here <code class="language-plaintext highlighter-rouge">OneHotEncoder()</code>. Lastly, we need to indicate which columns should be transformed, here done by giving column names <code class="language-plaintext highlighter-rouge">['pclass', 'sex', 'embarked']</code> but other forms (e.g., indices) also do work.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="p">(</span><span class="sh">'</span><span class="s">onehot</span><span class="sh">'</span><span class="p">,</span> <span class="nc">OneHotEncoder</span><span class="p">(),</span> <span class="p">[</span><span class="sh">'</span><span class="s">pclass</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sex</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">embarked</span><span class="sh">'</span><span class="p">])</span>
</pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>('onehot', OneHotEncoder(categorical_features=None, categories=None, drop=None,
               dtype=&lt;class 'numpy.float64'&gt;, handle_unknown='error',
               n_values=None, sparse=True), ['pclass', 'sex', 'embarked'])
</pre></table></code></div></div><p>The same is done with <code class="language-plaintext highlighter-rouge">StandardScaler()</code>. Since we have a few missing values in our features, we may implement an imputer as well. Luckily, sci-kit learn provides us with a simple imputer. At last, we need to tell the <code class="language-plaintext highlighter-rouge">ColumnTransformer</code> what happens to the features that are not selected for transformation in <code class="language-plaintext highlighter-rouge">remainder</code>. You can choose to just leave them as they are with <code class="language-plaintext highlighter-rouge">remainder = 'passthrough'</code>, to drop them, as I did, with <code class="language-plaintext highlighter-rouge">remainder = 'drop'</code> or to pass them to another estimator. Here is the finished <code class="language-plaintext highlighter-rouge">ColumnTransformer</code>:</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">preprocessor</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">imputer</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">constant</span><span class="sh">'</span><span class="p">,</span> <span class="n">fill_value</span> <span class="o">=</span> <span class="sh">'</span><span class="s">missing</span><span class="sh">'</span><span class="p">),</span>
          <span class="p">[</span><span class="sh">'</span><span class="s">pclass</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sex</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">embarked</span><span class="sh">'</span><span class="p">]),</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">onehot</span><span class="sh">'</span><span class="p">,</span> <span class="nc">OneHotEncoder</span><span class="p">(),</span> <span class="p">[</span><span class="sh">'</span><span class="s">pclass</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sex</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">embarked</span><span class="sh">'</span><span class="p">]),</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">imputer</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">median</span><span class="sh">'</span><span class="p">),</span>
          <span class="p">[</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sibsp</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">parch</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">fare</span><span class="sh">'</span><span class="p">]),</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">scaler</span><span class="sh">'</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">(),</span> <span class="p">[</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sibsp</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">parch</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">fare</span><span class="sh">'</span><span class="p">])</span>
    <span class="p">],</span>
    <span class="n">remainder</span> <span class="o">=</span> <span class="sh">'</span><span class="s">drop</span><span class="sh">'</span>
<span class="p">)</span>
</pre></table></code></div></div><p>This code looks a bit ugly. I prefer to split these lines into two sub-transformers, one for categorical features and one for numerical features.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># transformer for categorical features
</span><span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">pclass</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sex</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">embarked</span><span class="sh">'</span><span class="p">]</span>
<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">imputer_cat</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">constant</span><span class="sh">'</span><span class="p">,</span> <span class="n">fill_value</span> <span class="o">=</span> <span class="sh">'</span><span class="s">missing</span><span class="sh">'</span><span class="p">)),</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">onehot</span><span class="sh">'</span><span class="p">,</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span> <span class="o">=</span> <span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">))</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></table></code></div></div><p>Now, the steps for the numerical features:</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># transformer for numerical features
</span><span class="n">numeric_features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">age</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sibsp</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">parch</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">fare</span><span class="sh">'</span><span class="p">]</span>
<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">imputer_num</span><span class="sh">'</span><span class="p">,</span> <span class="nc">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="sh">'</span><span class="s">median</span><span class="sh">'</span><span class="p">)),</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">scaler</span><span class="sh">'</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">())</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></table></code></div></div><p>We combine them in a single <code class="language-plaintext highlighter-rouge">ColumnTransformer</code> again.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">preprocessor</span> <span class="o">=</span> <span class="nc">ColumnTransformer</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">categoricals</span><span class="sh">'</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">),</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">numericals</span><span class="sh">'</span><span class="p">,</span> <span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">remainder</span> <span class="o">=</span> <span class="sh">'</span><span class="s">drop</span><span class="sh">'</span>
<span class="p">)</span>
</pre></table></code></div></div><p>Next, we create the machine learning pipeline and include the column transformer as a step. <code class="language-plaintext highlighter-rouge">make_pipeline()</code> may shorten the code, but I find this representation clearer.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">preprocessing</span><span class="sh">'</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
        <span class="p">(</span><span class="sh">'</span><span class="s">clf</span><span class="sh">'</span><span class="p">,</span> <span class="nc">LogisticRegression</span><span class="p">())</span>
    <span class="p">]</span>
<span class="p">)</span>
</pre></table></code></div></div><p>Now that we have all preprocessing steps set, we can move on to hyperparameter tuning and estimation of model performance. I pass the candidate parameters as a dictionary here. Since we’ll feed a pipeline to <code class="language-plaintext highlighter-rouge">GridSearchCV()</code> later, we need to indicate what step a parameter belongs to. Adding ‘clf__’ for our pipeline step <code class="language-plaintext highlighter-rouge">('clf', LogisticRegression())</code> does the trick here.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">clf__solver</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">liblinear</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">clf__penalty</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">l1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">l2</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">clf__C</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">clf__random_state</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">42</span><span class="p">]</span>
<span class="p">}</span>
</pre></table></code></div></div><p>We still need to define a cross-validation strategy. I go for <code class="language-plaintext highlighter-rouge">RepeatedStratifiedKFold()</code> with $k = 5$. That means stratified 5-fold cross-validation repeated two times with a shuffling of the observations between the two repetitions.</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">rskf</span> <span class="o">=</span> <span class="nc">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</pre></table></code></div></div><p>Next, we create the <code class="language-plaintext highlighter-rouge">GridSearchCV()</code> object by filling in the steps above and choosing a scoring metric:</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">cv</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span>
  <span class="n">pipeline</span><span class="p">,</span>
  <span class="n">params</span><span class="p">,</span>
  <span class="n">cv</span> <span class="o">=</span> <span class="n">rskf</span><span class="p">,</span>
  <span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">],</span>
  <span class="n">refit</span> <span class="o">=</span> <span class="sh">'</span><span class="s">f1</span><span class="sh">'</span><span class="p">,</span>
  <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="p">)</span>
</pre></table></code></div></div><p>Split the data into features (X) and target (y):</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">survived</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">titanic</span><span class="p">.</span><span class="n">survived</span>
</pre></table></code></div></div><p>And, finally, execute and evaluate!</p><div lang="python" class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Best F1-score: </span><span class="si">{</span><span class="n">cv</span><span class="p">.</span><span class="n">best_score_</span><span class="si">:</span><span class="p">.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Best parameter set: </span><span class="si">{</span><span class="n">cv</span><span class="p">.</span><span class="n">best_params_</span><span class="si">}</span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Scores: </span><span class="si">{</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>Best F1-score: 0.712

Best parameter set: {'clf__C': 10, 'clf__penalty': 'l1', 'clf__random_state': 42, 'clf__solver': 'liblinear'}

Scores:               precision    recall  f1-score   support

           0       0.82      0.85      0.83       809
           1       0.74      0.69      0.72       500

    accuracy                           0.79      1309
   macro avg       0.78      0.77      0.77      1309
weighted avg       0.79      0.79      0.79      1309
</pre></table></code></div></div><p>Our best results, an F1-score of 0.712, were achieved with an inverse of regularization strength (<em>C</em>) of 10 and L1 penalty.</p><p>Find the complete code in one single file down below. Happy coding!</p><script src="https://gist.github.com/moritzkoerber/81c82f37e68b1140e406ac468a205f3f.js"></script></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2" ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=How to apply preprocessing steps in a pipeline only to specific features - Moritz Körber&url=https://moritzkoerber.github.io/posts/preprocessing-in-pipeline/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4" ><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/duckdb-soda/"><div class="card-body"> <span class="timeago small" >Jun 15, 2023<i class="unloaded">2023-06-15T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Add data quality checks to your duckdb pipeline with Soda Core</h3><div class="text-muted small"><p> duckdb is a great and fast choice for pipelines running on a single instance and is an even better match if you’re pipeline oozes with SQL. To ensure that what you are doing with duckdb is actually...</p></div></div></a></div><div class="card"> <a href="/posts/de-exercises/"><div class="card-body"> <span class="timeago small" >Apr 8, 2022<i class="unloaded">2022-04-08T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Data Engineering Practice</h3><div class="text-muted small"><p> Yesterday, I finished the last exercise of Daniel Beach’s amazing data engineering exercises. The exercises look simple at first glance, but in each exercise I stumbled upon something of which I th...</p></div></div></a></div><div class="card"> <a href="/posts/deploy-with-oidc/"><div class="card-body"> <span class="timeago small" >Nov 28, 2021<i class="unloaded">2021-11-28T00:00:00+01:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Simple and secure deployment with Github Actions OpenID Connect (OIDC)</h3><div class="text-muted small"><p> Continuous delivery (CD) workflows implemented Github Actions help deploy software, create and update cloud infrastructure, or make use of various services of cloud providers like Amazon Web Servic...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/missingno/" class="btn btn-outline-primary" prompt="Older"><p>A plot says more than 1000 tables: Visualizing missing data with missingno</p></a> <a href="/posts/preprocessing-hyperparameters/" class="btn btn-outline-primary" prompt="Newer"><p>Tune your preprocessing steps and algorithm selection like hyperparameters</p></a></div><div id="disqus" class="pt-2 pb-2"><p class="text-center text-muted small pb-5"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/js/lib/jquery.disqusloader.min.js"></script> <script> const options = { scriptUrl: '//moritzkoerber-com.disqus.com/embed.js', disqusConfig: function() { this.page.title = 'How to apply preprocessing steps in a pipeline only to specific features'; this.page.url = 'https://moritzkoerber.github.io/posts/preprocessing-in-pipeline/'; this.page.identifier = '/posts/preprocessing-in-pipeline/'; } }; $.disqusLoader('#disqus', options); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/moritzkoerber">Moritz Körber</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://moritzkoerber.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
