<!DOCTYPE html><html lang="en" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Prediction of the quality of physical exercise on the basis of accelerometer data" /><meta name="author" content="Moritz Körber" /><meta property="og:locale" content="en" /><meta name="description" content="Background" /><meta property="og:description" content="Background" /><link rel="canonical" href="https://moritzkoerber.github.io/posts/prediction-of-physical-exercise/" /><meta property="og:url" content="https://moritzkoerber.github.io/posts/prediction-of-physical-exercise/" /><meta property="og:site_name" content="Moritz Körber" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-07-24T00:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Prediction of the quality of physical exercise on the basis of accelerometer data" /><meta name="twitter:site" content="@moritzkoerber" /><meta name="twitter:creator" content="@Moritz Körber" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Moritz Körber"},"dateModified":"2025-10-01T20:43:32+02:00","datePublished":"2019-07-24T00:00:00+02:00","description":"Background","headline":"Prediction of the quality of physical exercise on the basis of accelerometer data","mainEntityOfPage":{"@type":"WebPage","@id":"https://moritzkoerber.github.io/posts/prediction-of-physical-exercise/"},"url":"https://moritzkoerber.github.io/posts/prediction-of-physical-exercise/"}</script><title>Prediction of the quality of physical exercise on the basis of accelerometer data | Moritz Körber</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Moritz Körber"><meta name="application-name" content="Moritz Körber"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/resources/images/pic.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Moritz Körber</a></div><div class="site-subtitle font-italic">Data science and other board games</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVE</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT ME</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/moritzkoerber" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/moritzkoerber" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href="https://medium.com/@moritzkoerber" aria-label="medium" target="_blank" rel="noopener"> <i class="fab fa-medium"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['moritzjkoerber','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/moritzkoerber/" aria-label="linkedin" target="_blank" rel="noopener"> <i class="fab fa-linkedin"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>Prediction of the quality of physical exercise on the basis of accelerometer data</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Prediction of the quality of physical exercise on the basis of accelerometer data</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Moritz Körber </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Jul 24, 2019, 12:00 AM +0200" >Jul 24, 2019<i class="unloaded">2019-07-24T00:00:00+02:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Wed, Oct 1, 2025, 8:43 PM +0200" >Oct 1, 2025<i class="unloaded">2025-10-01T20:43:32+02:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2004 words">11 min read</span></div></div><div class="post-content"><h2 id="background">Background</h2><p>Going to the gym, whether to boost your health, to lose weight, or simply because it is fun, is certainly a worthwhile activity. <a href="https://fivethirtyeight.com/features/its-easier-than-ever-to-get-the-recommended-amount-of-exercise/">FiveThirtyEight</a> recently reported that according to the latest <em>Physical Activity Guidelines for Americans</em>, every form of activity counts. However, if you have eager goals, not only quantity but also quality and being efficient matters. In this project, I predict whether a certain exercise, a barbell lift, was well or sloppily executed on the basis of data obtained from accelerometers on the belt, forearm, arm, and dumbell of six participants. The participants performed the exercises correctly and incorrectly in five different ways.</p><p>The idea for this analysis stems from the Coursera course <em>Practical Machine Learning</em> by Johns Hopkins University. The data for this project come from <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>.</p><h2 id="analysis">Analysis</h2><p>The first step is to load all required packages:</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">library</span><span class="p">(</span><span class="s2">"dplyr"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"caret"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"mlr"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"visdat"</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="s2">"data.table"</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p>Then I load the data set with the speedy <code class="language-plaintext highlighter-rouge">fread()</code> function of <code class="language-plaintext highlighter-rouge">data.table</code> and set a seed for reproducibility.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">fread</span><span class="p">(</span><span class="s2">"1_data/pml-training.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">na.strings</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"NA"</span><span class="p">,</span><span class="w"> </span><span class="s2">"NaN"</span><span class="p">,</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w"> </span><span class="s2">"#DIV/0!"</span><span class="p">),</span><span class="w"> </span><span class="n">drop</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">

</span><span class="n">set.seed</span><span class="p">(</span><span class="m">31</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h2 id="1-inspect-the-target-variable">1. Inspect the target variable</h2><p>First, I am looking at the target variable <code class="language-plaintext highlighter-rouge">classe</code>. What type is it, how many “classes” are there in the data set?</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">glimpse</span><span class="p">(</span><span class="n">df</span><span class="o">$</span><span class="n">classe</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>##  chr [1:19622] "A" "A" "A" "A" "A" "A" "A" "A" "A" "A" "A" "A" "A" "A" ...
</pre></table></code></div></div><p>Since it is a categorical variable, the analysis represents a classification problem. Hence, an algorithm like logistic regression or random forest is suitable. Let’s check if the classes are balanced:</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">classe</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_bar</span><span class="p">(</span><span class="n">stat</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"count"</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"#005293"</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">theme_classic</span><span class="p">()</span><span class="w">
</span></pre></table></code></div></div><p><img data-proofer-ignore data-src="/resources/images/2019-07-24-blogpost/unnamed-chunk-4-1.png" alt="" /></p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">count</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">classe</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>## # A tibble: 5 x 2
##   classe     n
##   &lt;chr&gt;  &lt;int&gt;
## 1 A       5580
## 2 B       3797
## 3 C       3422
## 4 D       3216
## 5 E       3607
</pre></table></code></div></div><p>The classes seem to be pretty balanced. This will make cross-validation and performance evaluation a bit easier.</p><h2 id="2-clean-the-data-set">2. Clean the data set</h2><p>First, I remove obviously non-predictive features such as <code class="language-plaintext highlighter-rouge">user_name</code>.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">df</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">select</span><span class="p">(</span><span class="o">-</span><span class="nf">c</span><span class="p">(</span><span class="n">raw_timestamp_part_1</span><span class="p">,</span><span class="w"> </span><span class="n">raw_timestamp_part_2</span><span class="p">,</span><span class="w"> </span><span class="n">cvtd_timestamp</span><span class="p">,</span><span class="w"> </span><span class="n">user_name</span><span class="p">))</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">df</span><span class="w">
</span></pre></table></code></div></div><p>Next, I am looking for zero variance/near zero variance features and remove them afterwards.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">nzv</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">nearZeroVar</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="n">..nzv</span><span class="p">]</span><span class="w">

</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">removeConstantFeatures</span><span class="p">(</span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">df</span><span class="p">),</span><span class="w"> </span><span class="n">perc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.02</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>## Removing 12 columns: kurtosis_picth_belt,skewness_roll_belt.1,kurtosis_roll_arm,kurtosis_picth_arm,skewness_roll_arm,skewness_pitch_arm,kurtosis_roll_forearm,kurtosis_picth_forearm,skewness_roll_forearm,skewness_pitch_forearm,max_yaw_forearm,min_yaw_forearm
</pre></table></code></div></div><p>The same goes for features that contain mostly NAs. I chose a cut-off of 97.5%, i.e. I remove a feature if 97.5% or more of its cases are NA. Before I mindlessly discard these predictors, I am having a closer look at them – cut-offs are comfortable but may be nonsensical sometimes.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">df</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="n">everything</span><span class="p">())</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">summarise_all</span><span class="p">(</span><span class="n">funs</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="nf">is.na</span><span class="p">(</span><span class="n">.</span><span class="p">))</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nf">length</span><span class="p">(</span><span class="n">.</span><span class="p">)))</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">p</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>## Warning: funs() is soft deprecated as of dplyr 0.8.0
## Please use a list of either functions or lambdas:
##
##   # Simple named list:
##   list(mean = mean, median = median)
##
##   # Auto named with `tibble::lst()`:
##   tibble::lst(mean, median)
##
##   # Using lambdas
##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))
## This warning is displayed once per session.
</pre></table></code></div></div><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># check these variables</span><span class="w">
</span><span class="n">vis_miss</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0.975</span><span class="p">)],</span><span class="w">
  </span><span class="n">sort_miss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">,</span><span class="w"> </span><span class="n">warn_large_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p><img data-proofer-ignore data-src="/resources/images/2019-07-24-blogpost/unnamed-chunk-7-1.png" alt="" /></p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># remove them if sensible</span><span class="w">
</span><span class="n">df</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">p</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="m">0.975</span><span class="p">)]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kc">NULL</span><span class="w">
</span></pre></table></code></div></div><p>Highly correlated features contain mostly the same information. Hence, keeping both does not have any value at best and hurts fitting the model at worst. I am looking for features that are highly correlated for this reason and discard them if it seems sensible.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">nums</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">select_if</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">is.numeric</span><span class="p">)</span><span class="w">
</span><span class="n">descrCor</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">cor</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span><span class="w">

</span><span class="n">highCorr</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="n">na.omit</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">descrCor</span><span class="p">[</span><span class="n">upper.tri</span><span class="p">(</span><span class="n">descrCor</span><span class="p">)]))</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="m">.98</span><span class="p">)</span><span class="w">

</span><span class="n">na.omit</span><span class="p">(</span><span class="n">descrCor</span><span class="p">[</span><span class="n">upper.tri</span><span class="p">(</span><span class="n">descrCor</span><span class="p">)])[</span><span class="n">which</span><span class="p">(</span><span class="n">na.omit</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">descrCor</span><span class="p">[</span><span class="n">upper.tri</span><span class="p">(</span><span class="n">descrCor</span><span class="p">)]))</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="m">.98</span><span class="p">,</span><span class="w"> </span><span class="n">arr.ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)]</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>## [1]  0.9809241 -0.9920085
</pre></table></code></div></div><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">which</span><span class="p">(</span><span class="n">na.omit</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">descrCor</span><span class="p">))</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="m">.98</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">na.omit</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">descrCor</span><span class="p">))</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">arr.ind</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>##                  row col
## total_accel_belt   5   2
## accel_belt_z      11   2
## roll_belt          2   5
## roll_belt          2  11
</pre></table></code></div></div><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">findCorrelation</span><span class="p">(</span><span class="n">na.omit</span><span class="p">(</span><span class="n">descrCor</span><span class="p">),</span><span class="w"> </span><span class="n">cutoff</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.98</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">exact</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>## Compare row 11  and column  2 with corr  0.992
##   Means:  0.266 vs 0.165 so flagging column 11
## Compare row 2  and column  5 with corr  0.981
##   Means:  0.247 vs 0.161 so flagging column 2
## All correlations &lt;= 0.98
</pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>## [1] "accel_belt_z" "roll_belt"
</pre></table></code></div></div><p>There are two variables with a very high correlation. I will leave them in the dataset for this time, but performing the rest of the analysis without them is certainly an interesting alley to go down.</p><p>The <code class="language-plaintext highlighter-rouge">mlr</code> package provides a similar, more concise function:</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">findLinearCombos</span><span class="p">(</span><span class="n">nums</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>## $linearCombos
## list()
##
## $remove
## NULL
</pre></table></code></div></div><h2 id="3-visualize-the-data">3. Visualize the data</h2><p>Time to take a step back and to have a look at the result of these cleaning steps.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">vis_dat</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">warn_large_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">F</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p><img data-proofer-ignore data-src="/resources/images/2019-07-24-blogpost/unnamed-chunk-10-1.png" alt="" /></p><p>Let’s see if there are mixed data types within a single feature.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">vis_guess</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p><img data-proofer-ignore data-src="/resources/images/2019-07-24-blogpost/unnamed-chunk-11-1.png" alt="" /></p><p>Plotting the relationship of the features with the target, <code class="language-plaintext highlighter-rouge">classe</code>, yields a first glimpse on potentially meaningful features.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">nums</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">unlist</span><span class="p">(</span><span class="n">lapply</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">is.numeric</span><span class="p">))</span><span class="w">
</span><span class="n">featurePlot</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">df</span><span class="p">)[</span><span class="n">nums</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="o">$</span><span class="n">classe</span><span class="p">,</span><span class="w"> </span><span class="n">plot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"strip"</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><figure> <img data-proofer-ignore data-src="/resources/images/2019-07-24-blogpost/plot_features.png" /></figure><p>Looks fine, let’s save the progress! We can now tinker around with a clean data set and can always return back to this state.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">saveRDS</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="s2">"1_data/cleaned_data.rds"</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h2 id="4-training">4. Training</h2><p>Since the training is a bit computational heavy, I outsourced this step and brought an Amazon AWS EC2 t2.2xlarge instance into play. I performed the training steps shown down below on this instance and then transferred the results to my own machine. Here are the details on its environment:</p><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
</pre><td class="rouge-code"><pre>## R version 3.6.0 (2019-04-26)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows Server x64 (build 17763)
##
## Matrix products: default
##
## locale:
## [1] LC_COLLATE=English_United States.1252
## [2] LC_CTYPE=English_United States.1252
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C
## [5] LC_TIME=English_United States.1252
##
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base
##
## other attached packages:
## [1] visdat_0.5.3      mlr_2.14.0        ParamHelpers_1.12 caret_6.0-84
## [5] ggplot2_3.1.1     lattice_0.20-38   dplyr_0.8.1
##
## loaded via a namespace (and not attached):
##  [1] gbm_2.1.5           tidyselect_0.2.5    purrr_0.3.2
##  [4] reshape2_1.4.3      splines_3.6.0       colorspace_1.4-1
##  [7] generics_0.0.2      stats4_3.6.0        survival_2.44-1.1
## [10] XML_3.98-1.19       prodlim_2018.04.18  rlang_0.3.4
## [13] ModelMetrics_1.2.2  pillar_1.4.0        glue_1.3.1
## [16] withr_2.1.2         xgboost_0.82.1      foreach_1.4.4
## [19] plyr_1.8.4          lava_1.6.5          stringr_1.4.0
## [22] timeDate_3043.102   munsell_0.5.0       gtable_0.3.0
## [25] recipes_0.1.5       codetools_0.2-16    parallelMap_1.4
## [28] parallel_3.6.0      class_7.3-15        Rcpp_1.0.1
## [31] scales_1.0.0        backports_1.1.4     checkmate_1.9.3
## [34] ipred_0.9-9         gridExtra_2.3       fastmatch_1.1-0
## [37] ranger_0.11.2       stringi_1.4.3       BBmisc_1.11
## [40] grid_3.6.0          tools_3.6.0         magrittr_1.5
## [43] lazyeval_0.2.2      tibble_2.1.1        randomForest_4.6-14
## [46] crayon_1.3.4        pkgconfig_2.0.2     MASS_7.3-51.4
## [49] Matrix_1.2-17       data.table_1.12.2   lubridate_1.7.4
## [52] gower_0.2.1         assertthat_0.2.1    iterators_1.0.10
## [55] R6_2.4.0            rpart_4.1-15        nnet_7.3-12
## [58] nlme_3.1-139        compiler_3.6.0
</pre></table></code></div></div><h3 id="task">Task</h3><p>What do we want our machine to learn? I first need to specify the data set and the target for prediction, here <code class="language-plaintext highlighter-rouge">classe</code>. In the <code class="language-plaintext highlighter-rouge">mlr</code> package, this is done by defining a task:</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">task</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeClassifTask</span><span class="p">(</span><span class="n">id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"fitness.tracker"</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"classe"</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h3 id="resampling">Resampling</h3><p>I chose to use a nested cross-validation strategy with a 5-fold inner cross-validation plan and a 3-fold outer cross-validation plan. Following the 3-fold outer cross-valdation plan, the data set is first split into 3 folds. Evaluation of the test error and hyperparameter tuning are performed using two of these folds by 5-fold cross-validation, the inner cross-validation plan:</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">rdesc.inner</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeResampleDesc</span><span class="p">(</span><span class="s2">"CV"</span><span class="p">,</span><span class="w"> </span><span class="n">iters</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p>The best parameter combination is then evaluated against the remaining fold of the 3-fold outer cross-validation plan:</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">rdesc.outer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeResampleDesc</span><span class="p">(</span><span class="n">method</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"CV"</span><span class="p">,</span><span class="w"> </span><span class="n">iters</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">3</span><span class="p">)</span><span class="w">
</span><span class="n">resample.instance.outer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeResampleInstance</span><span class="p">(</span><span class="n">desc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rdesc.outer</span><span class="p">,</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">task</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p>The <a href="https://mlr.mlr-org.com/index.html">mlr homepage</a> provides a great graphical representation of this strategy <a href="https://mlr.mlr-org.com/articles/tutorial/nested_resampling.html">here</a>.</p><figure style="width: 75%; margin: 0 auto;"> <img data-proofer-ignore data-src="/resources/images/2019-07-24-blogpost/nested_resampling.png" /><figcaption style="width: 100%; margin: 0 auto;">Note that the illustrated strategy uses a different number of folds.</figcaption></figure><h3 id="measures">Measures</h3><p>Since it is a classification problem and the classes seem to be balanced, I chose the mean misclassification error to evaluate the learners’ performance. Other metrics, such as accuracy or F1-score, would also have been suitable and are easy to add if necessary.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">measures</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="n">mmce</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h3 id="learners">Learners</h3><p>I compare the performance of three different learners: a random forest, XGBoost (a gradient boosting algorithm), and a ranger (a fast implementation of random forests). Each learner’s hyperparameters are tuned in the cross-validation process. For preprocessing, I center and scale the features. Here are the leaners’ instantiations:</p><h4 id="random-forest">Random forest</h4><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="n">lrn.rndforest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makePreprocWrapperCaret</span><span class="p">(</span><span class="s2">"classif.randomForest"</span><span class="p">,</span><span class="w"> </span><span class="n">ppc.center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">ppc.scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">

</span><span class="n">ps.rndforest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeParamSet</span><span class="p">(</span><span class="w">
  </span><span class="n">makeIntegerParam</span><span class="p">(</span><span class="s2">"ntree"</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">),</span><span class="w">
  </span><span class="n">makeIntegerParam</span><span class="p">(</span><span class="s2">"mtry"</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">tune.ctrl.rndforest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeTuneControlRandom</span><span class="p">(</span><span class="n">maxit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">)</span><span class="w">

</span><span class="n">tuned.lrn.rndforest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeTuneWrapper</span><span class="p">(</span><span class="n">lrn.rndforest</span><span class="p">,</span><span class="w">
  </span><span class="n">par.set</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ps.rndforest</span><span class="p">,</span><span class="w">
  </span><span class="n">resampling</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rdesc.inner</span><span class="p">,</span><span class="w">
  </span><span class="n">control</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tune.ctrl.rndforest</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h4 id="xgboost">XGBoost</h4><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">lrn.xgboost</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makePreprocWrapperCaret</span><span class="p">(</span><span class="s2">"classif.xgboost"</span><span class="p">,</span><span class="w"> </span><span class="n">ppc.center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">ppc.scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>## Warning in makeParam(id = id, type = "numeric", learner.param = TRUE, lower = lower, : NA used as a default value for learner parameter missing.
## ParamHelpers uses NA as a special value for dependent parameters.
</pre></table></code></div></div><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="n">ps.xgboost</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeParamSet</span><span class="p">(</span><span class="w">
  </span><span class="n">makeNumericParam</span><span class="p">(</span><span class="s2">"eta"</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">),</span><span class="w">
  </span><span class="n">makeNumericParam</span><span class="p">(</span><span class="s2">"colsample_bytree"</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.9</span><span class="p">),</span><span class="w">
  </span><span class="n">makeNumericParam</span><span class="p">(</span><span class="s2">"gamma"</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="p">),</span><span class="w">
  </span><span class="n">makeIntegerParam</span><span class="p">(</span><span class="s2">"max_depth"</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">4</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">),</span><span class="w">
  </span><span class="n">makeIntegerParam</span><span class="p">(</span><span class="s2">"nrounds"</span><span class="p">,</span><span class="w"> </span><span class="n">lower</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500</span><span class="p">,</span><span class="w"> </span><span class="n">upper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1500</span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">tune.ctrl.xgboost</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeTuneControlRandom</span><span class="p">(</span><span class="n">maxit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">30</span><span class="p">)</span><span class="w">

</span><span class="n">tuned.lrn.xgboost</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makeTuneWrapper</span><span class="p">(</span><span class="n">lrn.xgboost</span><span class="p">,</span><span class="w">
  </span><span class="n">par.set</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ps.xgboost</span><span class="p">,</span><span class="w">
  </span><span class="n">resampling</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rdesc.inner</span><span class="p">,</span><span class="w">
  </span><span class="n">control</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tune.ctrl.xgboost</span><span class="w">
</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h4 id="ranger">Ranger</h4><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">lrn.ranger</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">makePreprocWrapperCaret</span><span class="p">(</span><span class="s2">"classif.ranger"</span><span class="p">,</span><span class="w"> </span><span class="n">ppc.center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">,</span><span class="w"> </span><span class="n">ppc.scale</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">T</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h3 id="benchmark">Benchmark</h3><p>Let’s see how well each learner does!</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">bm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">benchmark</span><span class="p">(</span><span class="w">
  </span><span class="n">learners</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="w">
    </span><span class="n">tuned.lrn.rndforest</span><span class="p">,</span><span class="w">
    </span><span class="n">tuned.lrn.xgboost</span><span class="p">,</span><span class="w">
    </span><span class="n">lrn.ranger</span><span class="w">
  </span><span class="p">),</span><span class="w">
  </span><span class="n">tasks</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">task</span><span class="p">,</span><span class="w">
  </span><span class="n">resamplings</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">resample.instance.outer</span><span class="p">,</span><span class="w">
  </span><span class="n">measures</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">measures</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">bm</span><span class="w">
</span></pre></table></code></div></div><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">plotBMRBoxplots</span><span class="p">(</span><span class="n">bm</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p><img data-proofer-ignore data-src="/resources/images/2019-07-24-blogpost/unnamed-chunk-25-1.png" alt="" /></p><p>The XGBoost algorithm seems to do the best job here. Thus, I concentrate on this learner and go on with extended hyperparameter tuning. Next, I train the final model on the complete training data set and discard all others but the best performing hyperparameter set.</p><h2 id="5-train-final-model">5. Train final model</h2><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">mlr</span><span class="o">::</span><span class="n">train</span><span class="p">(</span><span class="n">learner</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tuned.lrn.xgboost</span><span class="p">,</span><span class="w"> </span><span class="n">task</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">task</span><span class="p">)</span><span class="w">

</span><span class="n">saveRDS</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="s2">"1_data/model.rds"</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><h2 id="6-predict-the-test-data">6. Predict the test data</h2><p>The last step of this analysis is to predict a small, completely new, and independent test set. First step again is to load the test data.</p><h3 id="load-and-prepare-test-data">Load and prepare test data</h3><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">testing</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">read.csv</span><span class="p">(</span><span class="s2">"1_data/pml-testing.csv"</span><span class="p">,</span><span class="w"> </span><span class="n">na.strings</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s2">"NA"</span><span class="p">,</span><span class="w"> </span><span class="s2">"NaN"</span><span class="p">,</span><span class="w"> </span><span class="s2">""</span><span class="p">,</span><span class="w"> </span><span class="s2">"#DIV/0!"</span><span class="p">),</span><span class="w"> </span><span class="n">row.names</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="w">

</span><span class="c1"># make sure that they have the same columns (except the target)</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="o">-</span><span class="n">classe</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w">
  </span><span class="n">colnames</span><span class="p">()</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">vars</span><span class="w">

</span><span class="n">testing</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">testing</span><span class="p">[</span><span class="n">vars</span><span class="p">]</span><span class="w">
</span></pre></table></code></div></div><h3 id="prediction">Prediction</h3><p>I use the model trained above to predict the 20 cases in this final test set.</p><div lang="r" class="language-r highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pred</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">newdata</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">testing</span><span class="p">)</span><span class="w">
</span></pre></table></code></div></div><p>Let’s see how we did here:</p><div lang="plaintext" class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre>##    response true_labels correct_prediction
## 1         B           B                yes
## 2         A           A                yes
## 3         B           B                yes
## 4         A           A                yes
## 5         A           A                yes
## 6         E           E                yes
## 7         D           D                yes
## 8         B           B                yes
## 9         A           A                yes
## 10        A           A                yes
## 11        B           B                yes
## 12        C           C                yes
## 13        B           B                yes
## 14        A           A                yes
## 15        E           E                yes
## 16        E           E                yes
## 17        A           A                yes
## 18        B           B                yes
## 19        B           B                yes
## 20        B           B                yes
</pre></table></code></div></div><p>Seems like the learner did a great job! It predicted every case correctly. Yay! :)</p><p>Github repo for this blogpost: <a href="https://github.com/moritzkoerber/accelerometer_data_analysis">https://github.com/moritzkoerber/accelerometer_data_analysis</a></p></div><div class="post-tail-wrapper text-muted"><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2" ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Prediction of the quality of physical exercise on the basis of accelerometer data - Moritz Körber&url=https://moritzkoerber.github.io/posts/prediction-of-physical-exercise/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink('', 'Link copied successfully!')" data-toggle="tooltip" data-placement="top" title="Copy link"> </i> </span></div></div></div></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4" ><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/duckdb-soda/"><div class="card-body"> <span class="timeago small" >Jun 15, 2023<i class="unloaded">2023-06-15T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Add data quality checks to your duckdb pipeline with Soda Core</h3><div class="text-muted small"><p> duckdb is a great and fast choice for pipelines running on a single instance and is an even better match if you’re pipeline oozes with SQL. To ensure that what you are doing with duckdb is actually...</p></div></div></a></div><div class="card"> <a href="/posts/de-exercises/"><div class="card-body"> <span class="timeago small" >Apr 8, 2022<i class="unloaded">2022-04-08T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Data Engineering Practice</h3><div class="text-muted small"><p> Yesterday, I finished the last exercise of Daniel Beach’s amazing data engineering exercises. The exercises look simple at first glance, but in each exercise I stumbled upon something of which I th...</p></div></div></a></div><div class="card"> <a href="/posts/deploy-with-oidc/"><div class="card-body"> <span class="timeago small" >Nov 28, 2021<i class="unloaded">2021-11-28T00:00:00+01:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Simple and secure deployment with Github Actions OpenID Connect (OIDC)</h3><div class="text-muted small"><p> Continuous delivery (CD) workflows implemented Github Actions help deploy software, create and update cloud infrastructure, or make use of various services of cloud providers like Amazon Web Servic...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <span class="btn btn-outline-primary disabled" prompt="Older"><p>-</p></span> <a href="/posts/missingno/" class="btn btn-outline-primary" prompt="Newer"><p>A plot says more than 1000 tables: Visualizing missing data with missingno</p></a></div><div id="disqus" class="pt-2 pb-2"><p class="text-center text-muted small pb-5"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/js/lib/jquery.disqusloader.min.js"></script> <script> const options = { scriptUrl: '//moritzkoerber-com.disqus.com/embed.js', disqusConfig: function() { this.page.title = 'Prediction of the quality of physical exercise on the basis of accelerometer data'; this.page.url = 'https://moritzkoerber.github.io/posts/prediction-of-physical-exercise/'; this.page.identifier = '/posts/prediction-of-physical-exercise/'; } }; $.disqusLoader('#disqus', options); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/moritzkoerber">Moritz Körber</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://moritzkoerber.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
